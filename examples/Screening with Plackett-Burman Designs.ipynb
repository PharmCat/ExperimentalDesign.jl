{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This a short guide on how to generate *Plackett-Burman* designs for screening and computing main effects of factors using a linear model fit. For more information, check the [documentation](https://phrb.github.io/ExperimentalDesign.jl/dev/).\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, check if you are at the correct project environment. It should be `ExperimentalDesign`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mProject \u001b[22m\u001b[39mExperimentalDesign v0.2.0\n",
      "\u001b[32m\u001b[1m    Status\u001b[22m\u001b[39m `~/.julia/dev/ExperimentalDesign/Project.toml`\n",
      " \u001b[90m [a93c6f00]\u001b[39m\u001b[37m DataFrames v0.20.2\u001b[39m\n",
      " \u001b[90m [864edb3b]\u001b[39m\u001b[37m DataStructures v0.17.10\u001b[39m\n",
      " \u001b[90m [31c24e10]\u001b[39m\u001b[37m Distributions v0.22.6\u001b[39m\n",
      " \u001b[90m [ffbed154]\u001b[39m\u001b[37m DocStringExtensions v0.8.1\u001b[39m\n",
      " \u001b[90m [e30172f5]\u001b[39m\u001b[37m Documenter v0.24.6\u001b[39m\n",
      " \u001b[90m [38e38edf]\u001b[39m\u001b[37m GLM v1.3.7\u001b[39m\n",
      " \u001b[90m [27ebfcd6]\u001b[39m\u001b[37m Primes v0.4.0\u001b[39m\n",
      " \u001b[90m [2913bbd2]\u001b[39m\u001b[37m StatsBase v0.32.2\u001b[39m\n",
      " \u001b[90m [3eaba693]\u001b[39m\u001b[37m StatsModels v0.6.10\u001b[39m\n",
      " \u001b[90m [37e2e46d]\u001b[39m\u001b[37m LinearAlgebra \u001b[39m\n",
      " \u001b[90m [56ddb016]\u001b[39m\u001b[37m Logging \u001b[39m\n",
      " \u001b[90m [9a3f8284]\u001b[39m\u001b[37m Random \u001b[39m\n",
      " \u001b[90m [8dfed614]\u001b[39m\u001b[37m Test \u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then check if all packages are installed and up to date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[2K\u001b[?25h[1mFetching:\u001b[22m\u001b[39m [========================================>]  100.0 %.0 %\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/dev/ExperimentalDesign/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/dev/ExperimentalDesign/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "Pkg.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ExperimentalDesign, StatsModels, GLM, DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Plackett-Burman Designs\n",
    "\n",
    "A Plackett-Burman design is an orthogonal design matrix for factors $f_1,\\dots,f_N$. Factors are encoded by high and low values, which can be mapped to the interval $[-1, 1]$. For designs in this package, the design matrix is a `DataFrame` from the [DataFrame package](https://juliastats.org/GLM.jl/stable/). For example, let's create a Plackett-Burman design for 6 factors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>factor1</th><th>factor2</th><th>factor3</th><th>factor4</th><th>factor5</th><th>factor6</th><th>dummy1</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>8 rows × 7 columns</p><tr><th>1</th><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr><tr><th>2</th><td>-1</td><td>1</td><td>-1</td><td>1</td><td>1</td><td>-1</td><td>-1</td></tr><tr><th>3</th><td>1</td><td>-1</td><td>1</td><td>1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><th>4</th><td>-1</td><td>1</td><td>1</td><td>-1</td><td>-1</td><td>-1</td><td>1</td></tr><tr><th>5</th><td>1</td><td>1</td><td>-1</td><td>-1</td><td>-1</td><td>1</td><td>-1</td></tr><tr><th>6</th><td>1</td><td>-1</td><td>-1</td><td>-1</td><td>1</td><td>-1</td><td>1</td></tr><tr><th>7</th><td>-1</td><td>-1</td><td>-1</td><td>1</td><td>-1</td><td>1</td><td>1</td></tr><tr><th>8</th><td>-1</td><td>-1</td><td>1</td><td>-1</td><td>1</td><td>1</td><td>-1</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& factor1 & factor2 & factor3 & factor4 & factor5 & factor6 & dummy1\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\\\\n",
       "\t2 & -1 & 1 & -1 & 1 & 1 & -1 & -1 \\\\\n",
       "\t3 & 1 & -1 & 1 & 1 & -1 & -1 & -1 \\\\\n",
       "\t4 & -1 & 1 & 1 & -1 & -1 & -1 & 1 \\\\\n",
       "\t5 & 1 & 1 & -1 & -1 & -1 & 1 & -1 \\\\\n",
       "\t6 & 1 & -1 & -1 & -1 & 1 & -1 & 1 \\\\\n",
       "\t7 & -1 & -1 & -1 & 1 & -1 & 1 & 1 \\\\\n",
       "\t8 & -1 & -1 & 1 & -1 & 1 & 1 & -1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "8×7 DataFrame\n",
       "│ Row │ factor1 │ factor2 │ factor3 │ factor4 │ factor5 │ factor6 │ dummy1 │\n",
       "│     │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m  │\n",
       "├─────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┤\n",
       "│ 1   │ 1       │ 1       │ 1       │ 1       │ 1       │ 1       │ 1      │\n",
       "│ 2   │ -1      │ 1       │ -1      │ 1       │ 1       │ -1      │ -1     │\n",
       "│ 3   │ 1       │ -1      │ 1       │ 1       │ -1      │ -1      │ -1     │\n",
       "│ 4   │ -1      │ 1       │ 1       │ -1      │ -1      │ -1      │ 1      │\n",
       "│ 5   │ 1       │ 1       │ -1      │ -1      │ -1      │ 1       │ -1     │\n",
       "│ 6   │ 1       │ -1      │ -1      │ -1      │ 1       │ -1      │ 1      │\n",
       "│ 7   │ -1      │ -1      │ -1      │ 1       │ -1      │ 1       │ 1      │\n",
       "│ 8   │ -1      │ -1      │ 1       │ -1      │ 1       │ 1       │ -1     │"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "design = PlackettBurman(6)\n",
    "design.matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it is not possible to construct exact Plackett-Burman designs for all numbers of factors. In the example above, we needed a seventh extra \"dummy\" column to construct the design for six factors.\n",
    "\n",
    "Using the `PlackettBurman` allows quick construction of minimal screening designs for scenarios where we ignore interactions. We can access the underlying formula, which is a `Term` object from the [StatsModels package](https://juliastats.org/StatsModels.jl/stable/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response ~ -1 + factor1 + factor2 + factor3 + factor4 + factor5 + factor6 + dummy1\n"
     ]
    }
   ],
   "source": [
    "println(design.formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we ignore interactions and include the dummy factor in the model. Strong main effects attributed to dummy factors may indicate important interactions.\n",
    "\n",
    "We can obtain a tuple with the names of dummy factors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(:dummy1,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "design.dummy_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the main factors tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(:factor1, :factor2, :factor3, :factor4, :factor5, :factor6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "design.factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check other constructors on [the docs](https://phrb.github.io/ExperimentalDesign.jl/dev/lib/public/#ExperimentalDesign.PlackettBurman-Tuple{Int64})."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Main Effects\n",
    "\n",
    "Suppose that the response variable on the experiments specified in our screening design is computed by:\n",
    "\n",
    "$$\n",
    "y = 1.2 + (2.3f_1) + (-3.4f_2) + (7.12f_3) + (-0.03f_4) + (1.1f_5) + (-0.5f_6) + \\varepsilon\n",
    "$$\n",
    "\n",
    "The coefficients we want to estimate are:\n",
    "\n",
    "| Intercept | factor1 | factor2 | factor3 | factor4 | factor5 | factor6 |\n",
    "|---|---|---|---|---|---|---|\n",
    "| 1.2 | 2.3 | -3.4 | 7.12 | -0.03 | 1.1 | -0.5 |\n",
    "\n",
    "The corresponding Julia function is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function y(x)\n",
    "    return (1.2) +\n",
    "           (2.3 * x[1]) +\n",
    "           (-3.4 * x[2]) +\n",
    "           (7.12 * x[3]) +\n",
    "           (-0.03 * x[4]) +\n",
    "           (1.1 * x[5]) +\n",
    "           (-0.5 * x[6]) +\n",
    "           (1.1 * randn())\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the response column for our design using the cell below. Recall that the default is to call the response column `:response`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>factor1</th><th>factor2</th><th>factor3</th><th>factor4</th><th>factor5</th><th>factor6</th><th>dummy1</th><th>response</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Float64</th></tr></thead><tbody><p>8 rows × 8 columns</p><tr><th>1</th><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>7.65914</td></tr><tr><th>2</th><td>-1</td><td>1</td><td>-1</td><td>1</td><td>1</td><td>-1</td><td>-1</td><td>-10.3243</td></tr><tr><th>3</th><td>1</td><td>-1</td><td>1</td><td>1</td><td>-1</td><td>-1</td><td>-1</td><td>13.3226</td></tr><tr><th>4</th><td>-1</td><td>1</td><td>1</td><td>-1</td><td>-1</td><td>-1</td><td>1</td><td>2.33105</td></tr><tr><th>5</th><td>1</td><td>1</td><td>-1</td><td>-1</td><td>-1</td><td>1</td><td>-1</td><td>-7.77123</td></tr><tr><th>6</th><td>1</td><td>-1</td><td>-1</td><td>-1</td><td>1</td><td>-1</td><td>1</td><td>-0.120945</td></tr><tr><th>7</th><td>-1</td><td>-1</td><td>-1</td><td>1</td><td>-1</td><td>1</td><td>1</td><td>-6.20142</td></tr><tr><th>8</th><td>-1</td><td>-1</td><td>1</td><td>-1</td><td>1</td><td>1</td><td>-1</td><td>9.9957</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& factor1 & factor2 & factor3 & factor4 & factor5 & factor6 & dummy1 & response\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 7.65914 \\\\\n",
       "\t2 & -1 & 1 & -1 & 1 & 1 & -1 & -1 & -10.3243 \\\\\n",
       "\t3 & 1 & -1 & 1 & 1 & -1 & -1 & -1 & 13.3226 \\\\\n",
       "\t4 & -1 & 1 & 1 & -1 & -1 & -1 & 1 & 2.33105 \\\\\n",
       "\t5 & 1 & 1 & -1 & -1 & -1 & 1 & -1 & -7.77123 \\\\\n",
       "\t6 & 1 & -1 & -1 & -1 & 1 & -1 & 1 & -0.120945 \\\\\n",
       "\t7 & -1 & -1 & -1 & 1 & -1 & 1 & 1 & -6.20142 \\\\\n",
       "\t8 & -1 & -1 & 1 & -1 & 1 & 1 & -1 & 9.9957 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "8×8 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ factor1 │ factor2 │ factor3 │ factor4 │ factor5 │ factor6 │ dummy1 │\n",
       "│     │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m  │\n",
       "├─────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┤\n",
       "│ 1   │ 1       │ 1       │ 1       │ 1       │ 1       │ 1       │ 1      │\n",
       "│ 2   │ -1      │ 1       │ -1      │ 1       │ 1       │ -1      │ -1     │\n",
       "│ 3   │ 1       │ -1      │ 1       │ 1       │ -1      │ -1      │ -1     │\n",
       "│ 4   │ -1      │ 1       │ 1       │ -1      │ -1      │ -1      │ 1      │\n",
       "│ 5   │ 1       │ 1       │ -1      │ -1      │ -1      │ 1       │ -1     │\n",
       "│ 6   │ 1       │ -1      │ -1      │ -1      │ 1       │ -1      │ 1      │\n",
       "│ 7   │ -1      │ -1      │ -1      │ 1       │ -1      │ 1       │ 1      │\n",
       "│ 8   │ -1      │ -1      │ 1       │ -1      │ 1       │ 1       │ -1     │"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "design.matrix[!, :response] = y.(eachrow(design.matrix[:, collect(design.factors)]))\n",
    "design.matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use the `lm` function from the [GLM package](https://juliastats.org/GLM.jl/stable/) to fit a linear model using the design's matrix and formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Array{Float64,1}},GLM.DensePredChol{Float64,LinearAlgebra.Cholesky{Float64,Array{Float64,2}}}},Array{Float64,2}}\n",
       "\n",
       "response ~ 0 + factor1 + factor2 + factor3 + factor4 + factor5 + factor6 + dummy1\n",
       "\n",
       "Coefficients:\n",
       "─────────────────────────────────────────────────────────────────────────\n",
       "          Estimate  Std. Error    t value  Pr(>|t|)  Lower 95%  Upper 95%\n",
       "─────────────────────────────────────────────────────────────────────────\n",
       "factor1   2.07425      1.60867   1.28942     0.4199   -18.3659    22.5144\n",
       "factor2  -3.76248      1.60867  -2.33887     0.2572   -24.2026    16.6776\n",
       "factor3   6.92894      1.60867   4.30724     0.1452   -13.5112    27.3691\n",
       "factor4   0.165416     1.60867   0.102828    0.9348   -20.2747    20.6055\n",
       "factor5   1.26416      1.60867   0.78584     0.5760   -19.176     21.7043\n",
       "factor6  -0.26782      1.60867  -0.166485    0.8950   -20.7079    20.1723\n",
       "dummy1   -0.409582     1.60867  -0.254609    0.8413   -20.8497    20.0305\n",
       "─────────────────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(design.formula, design.matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below shows the coefficients estimated by the linear model fit using the Plackett-Burman Design. The purpose of a screening design is not to estimate the actual coefficients, but instead to compute factor main effects. Note that standard errors are the same for every factor estimate. This happens because the design is orthogonal.\n",
    "\n",
    "| | Intercept | factor1 | factor2 | factor3 | factor4 | factor5 | factor6 | dummy1 |\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "| Original | 1.2 | 2.3 | -3.4 | 7.12 | -0.03 | 1.1 | -0.5 | $-$ |\n",
    "| Plackett-Burman Main Effects | $-$ | 2.07425 | -3.76248 | 6.92894 | 0.165416 | 1.26416 | -0.26782 | -0.409582 |\n",
    "\n",
    "We can use the coefficient magnitudes to infer that factor 3 probably has a strong main effect, and that factor 6 has not. Our dummy column had a relatively small coefficient estimate, so we could attempt to ignore interactions on subsequent experiments.\n",
    "\n",
    "# Fitting a Linear Model\n",
    "\n",
    "We can also try to fit a linear model on our design data in order to estimate coefficients. We would need to drop the dummy column and add the intercept term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Array{Float64,1}},GLM.DensePredChol{Float64,LinearAlgebra.Cholesky{Float64,Array{Float64,2}}}},Array{Float64,2}}\n",
       "\n",
       "response ~ 1 + factor1 + factor2 + factor3 + factor4 + factor5 + factor6\n",
       "\n",
       "Coefficients:\n",
       "────────────────────────────────────────────────────────────────────────────────\n",
       "               Estimate  Std. Error      t value  Pr(>|t|)  Lower 95%  Upper 95%\n",
       "────────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)   1.11133      0.194373    5.71751      0.1102  -1.35841     3.58107\n",
       "factor1       2.16107      0.194373   11.1182       0.0571  -0.308673    4.63081\n",
       "factor2      -3.13766      0.194373  -16.1425       0.0394  -5.6074     -0.66792\n",
       "factor3       7.2158       0.194373   37.1235       0.0171   4.74606     9.68554\n",
       "factor4       0.0026864    0.194373    0.0138208    0.9912  -2.46706     2.47243\n",
       "factor5       0.691073     0.194373    3.5554       0.1745  -1.77867     3.16081\n",
       "factor6      -0.190781     0.194373   -0.981522     0.5059  -2.66052     2.27896\n",
       "────────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(term(:response) ~ sum(term.(design.factors)), design.matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our table so far looks like this:\n",
    "\n",
    "| | Intercept | factor1 | factor2 | factor3 | factor4 | factor5 | factor6 | dummy1 |\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "| Original | 1.2 | 2.3 | -3.4 | 7.12 | -0.03 | 1.1 | -0.5 | $-$ |\n",
    "| Plackett-Burman Main Effects | $-$ | 2.07425 | -3.76248 | 6.92894 | 0.165416 | 1.26416 | -0.26782 | -0.409582 |\n",
    "| Plackett-Burman Estimate | 1.11133 | 2.16107 | -3.13766 | 7.2158 | 0.0026864 | 0.691073 | -0.190781 | $-$ |\n",
    "\n",
    "Notice that, since the standard errors are the same for all factors, factors with stronger main effects are better estimated. Notice that, despite the \"good\" coefficient estimates, the confidence intervals are really large.\n",
    "\n",
    "This is a biased comparison where the screening design \"works\" for coefficient estimation as well, but we would rather use fractional factorial or optimal designs to estimate the coefficients of factors with strong effects. Screening should be used to compute main effects and identifying which factors to test next.\n",
    "\n",
    "# Generating Random Designs\n",
    "\n",
    "We can also compare the coefficients produced by the same linear model fit, but using a random design. For more information, check [the docs](https://phrb.github.io/ExperimentalDesign.jl/dev/lib/public/#ExperimentalDesign.RandomDesign-Tuple{NamedTuple})."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>factor1</th><th>factor2</th><th>factor3</th><th>factor4</th><th>factor5</th><th>factor6</th><th>response</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>8 rows × 7 columns</p><tr><th>1</th><td>-0.427031</td><td>-0.257169</td><td>-0.0897106</td><td>-0.294582</td><td>-0.558218</td><td>-0.393435</td><td>0.476253</td></tr><tr><th>2</th><td>0.603076</td><td>-0.254854</td><td>-0.665052</td><td>-0.730241</td><td>0.646543</td><td>-0.501497</td><td>-2.19561</td></tr><tr><th>3</th><td>-0.271607</td><td>-0.280673</td><td>-0.403478</td><td>0.141009</td><td>0.279953</td><td>-0.107181</td><td>-3.4743</td></tr><tr><th>4</th><td>-0.188718</td><td>-0.865998</td><td>-0.545536</td><td>-0.823412</td><td>0.418322</td><td>-0.912559</td><td>-1.00517</td></tr><tr><th>5</th><td>0.545568</td><td>0.912846</td><td>0.70278</td><td>0.210541</td><td>-0.865226</td><td>0.554044</td><td>2.33168</td></tr><tr><th>6</th><td>0.894642</td><td>0.553883</td><td>0.638578</td><td>0.304812</td><td>0.553461</td><td>0.283002</td><td>6.69112</td></tr><tr><th>7</th><td>0.139338</td><td>0.108341</td><td>-0.352455</td><td>-0.27172</td><td>0.891287</td><td>-0.226327</td><td>0.125907</td></tr><tr><th>8</th><td>-0.275804</td><td>0.317014</td><td>-0.992121</td><td>-0.893386</td><td>-0.182471</td><td>0.5529</td><td>-6.32122</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& factor1 & factor2 & factor3 & factor4 & factor5 & factor6 & response\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & -0.427031 & -0.257169 & -0.0897106 & -0.294582 & -0.558218 & -0.393435 & 0.476253 \\\\\n",
       "\t2 & 0.603076 & -0.254854 & -0.665052 & -0.730241 & 0.646543 & -0.501497 & -2.19561 \\\\\n",
       "\t3 & -0.271607 & -0.280673 & -0.403478 & 0.141009 & 0.279953 & -0.107181 & -3.4743 \\\\\n",
       "\t4 & -0.188718 & -0.865998 & -0.545536 & -0.823412 & 0.418322 & -0.912559 & -1.00517 \\\\\n",
       "\t5 & 0.545568 & 0.912846 & 0.70278 & 0.210541 & -0.865226 & 0.554044 & 2.33168 \\\\\n",
       "\t6 & 0.894642 & 0.553883 & 0.638578 & 0.304812 & 0.553461 & 0.283002 & 6.69112 \\\\\n",
       "\t7 & 0.139338 & 0.108341 & -0.352455 & -0.27172 & 0.891287 & -0.226327 & 0.125907 \\\\\n",
       "\t8 & -0.275804 & 0.317014 & -0.992121 & -0.893386 & -0.182471 & 0.5529 & -6.32122 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "8×7 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ factor1   │ factor2   │ factor3    │ factor4   │ factor5   │ factor6   │\n",
       "│     │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │\n",
       "├─────┼───────────┼───────────┼────────────┼───────────┼───────────┼───────────┤\n",
       "│ 1   │ -0.427031 │ -0.257169 │ -0.0897106 │ -0.294582 │ -0.558218 │ -0.393435 │\n",
       "│ 2   │ 0.603076  │ -0.254854 │ -0.665052  │ -0.730241 │ 0.646543  │ -0.501497 │\n",
       "│ 3   │ -0.271607 │ -0.280673 │ -0.403478  │ 0.141009  │ 0.279953  │ -0.107181 │\n",
       "│ 4   │ -0.188718 │ -0.865998 │ -0.545536  │ -0.823412 │ 0.418322  │ -0.912559 │\n",
       "│ 5   │ 0.545568  │ 0.912846  │ 0.70278    │ 0.210541  │ -0.865226 │ 0.554044  │\n",
       "│ 6   │ 0.894642  │ 0.553883  │ 0.638578   │ 0.304812  │ 0.553461  │ 0.283002  │\n",
       "│ 7   │ 0.139338  │ 0.108341  │ -0.352455  │ -0.27172  │ 0.891287  │ -0.226327 │\n",
       "│ 8   │ -0.275804 │ 0.317014  │ -0.992121  │ -0.893386 │ -0.182471 │ 0.5529    │"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_design_generator = RandomDesign(tuple(fill(Uniform(-1, 1), 6)...))\n",
    "random_design = rand(random_design_generator, 8)\n",
    "\n",
    "random_design[!, :response] = y.(eachrow(random_design[:, :]))\n",
    "random_design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Array{Float64,1}},GLM.DensePredChol{Float64,LinearAlgebra.Cholesky{Float64,Array{Float64,2}}}},Array{Float64,2}}\n",
       "\n",
       "response ~ 1 + factor1 + factor2 + factor3 + factor4 + factor5 + factor6\n",
       "\n",
       "Coefficients:\n",
       "─────────────────────────────────────────────────────────────────────────────\n",
       "              Estimate  Std. Error    t value  Pr(>|t|)  Lower 95%  Upper 95%\n",
       "─────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)   2.00407     0.769246   2.60524     0.2333   -7.77013   11.7783 \n",
       "factor1       0.970606    0.974792   0.995706    0.5014  -11.4153    13.3565 \n",
       "factor2      -1.99341     1.04673   -1.90441     0.3078  -15.2934    11.3066 \n",
       "factor3       8.72217     2.01669    4.32499     0.1447  -16.9023    34.3467 \n",
       "factor4      -2.35305     1.40052   -1.68012     0.3418  -20.1484    15.4423 \n",
       "factor5       0.85805     1.80866    0.474413    0.7180  -22.1231    23.8392 \n",
       "factor6      -3.83447     0.995831  -3.85052     0.1618  -16.4877     8.81876\n",
       "─────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(random_design_generator.formula, random_design)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our table looks like this:\n",
    "\n",
    "| | Intercept | factor1 | factor2 | factor3 | factor4 | factor5 | factor6 | dummy1 |\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "| Original | 1.2 | 2.3 | -3.4 | 7.12 | -0.03 | 1.1 | -0.5 | $-$ |\n",
    "| Plackett-Burman Main Effects | $-$ | 2.07425 | -3.76248 | 6.92894 | 0.165416 | 1.26416 | -0.26782 | -0.409582 |\n",
    "| Plackett-Burman Estimate | 1.11133 | 2.16107 | -3.13766 | 7.2158 | 0.0026864 | 0.691073 | -0.190781 | $-$ |\n",
    "| Single Random Design Estimate | -0.330846 | -11.0202 | 7.32197 | 12.225 | 11.8927 | 19.5051 | 7.6392 | $-$ |\n",
    "\n",
    "The estimates produced using random designs will have larger confidence intervals, and therefore increased variability. The Plackett-Burman design is fixed, but can be randomised. The variability of main effects estimates using screening designs will depend on measurement or model error.\n",
    "\n",
    "# Generating Full Factorial Designs\n",
    "\n",
    "In this toy example, it is possible to generate all the possible combinations of six binary factors and compute the response. Although it costs 64 experiments, the linear model fit for the full factorial design should produce the best coefficient estimates.\n",
    "\n",
    "The `explicit` parameter below make the full factorial a complete `DataFrame` in memory. Since factorial designs can be prohibitively large, you can omit the `explicit` parameter, or set it to `false`, to create an iterator that will generate design lines on demand. For more, check [the docs](https://phrb.github.io/ExperimentalDesign.jl/dev/lib/public/#ExperimentalDesign.FullFactorial-Tuple{NamedTuple,StatsModels.FormulaTerm})."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Array{Float64,1}},GLM.DensePredChol{Float64,LinearAlgebra.Cholesky{Float64,Array{Float64,2}}}},Array{Float64,2}}\n",
       "\n",
       "response ~ 1 + factor1 + factor2 + factor3 + factor4 + factor5 + factor6\n",
       "\n",
       "Coefficients:\n",
       "───────────────────────────────────────────────────────────────────────────────\n",
       "               Estimate  Std. Error     t value  Pr(>|t|)  Lower 95%  Upper 95%\n",
       "───────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)   1.16675      0.142544    8.18519     <1e-10   0.881308   1.45219 \n",
       "factor1       2.19939      0.142544   15.4296      <1e-21   1.91396    2.48483 \n",
       "factor2      -3.35801      0.142544  -23.5578      <1e-30  -3.64345   -3.07257 \n",
       "factor3       7.23984      0.142544   50.7903      <1e-48   6.9544     7.52528 \n",
       "factor4      -0.0439413    0.142544   -0.308265    0.7590  -0.32938    0.241498\n",
       "factor5       0.947299     0.142544    6.64568     <1e-7    0.66186    1.23274 \n",
       "factor6      -0.43131      0.142544   -3.02581     0.0037  -0.716749  -0.145871\n",
       "───────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorial_design = FullFactorial(tuple(fill((-1, 1), 6)...), explicit = true)\n",
    "factorial_design.matrix\n",
    "\n",
    "factorial_design.matrix[!, :response] = y.(eachrow(factorial_design.matrix[:, :]))\n",
    "factorial_design.matrix\n",
    "\n",
    "lm(factorial_design.formula, factorial_design.matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidence intervals for this fit are much smaller. Since we have all information on all factors and this is a balanced design, the standard error is the same for all estimates. Here's the complete table:\n",
    "\n",
    "| | Intercept | factor1 | factor2 | factor3 | factor4 | factor5 | factor6 | dummy1 |\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "| Original | 1.2 | 2.3 | -3.4 | 7.12 | -0.03 | 1.1 | -0.5 | $-$ |\n",
    "| Plackett-Burman Main Effects | $-$ | 2.07425 | -3.76248 | 6.92894 | 0.165416 | 1.26416 | -0.26782 | -0.409582 |\n",
    "| Plackett-Burman Estimate | 1.11133 | 2.16107 | -3.13766 | 7.2158 | 0.0026864 | 0.691073 | -0.190781 | $-$ |\n",
    "| Single Random Design Estimate | -0.330846 | -11.0202 | 7.32197 | 12.225 | 11.8927 | 19.5051 | 7.6392 | $-$ |\n",
    "| Full Factorial Estimate | 1.16313 | 2.23662 | -3.55696 | 7.03516 | -0.102358 | 0.987681 | -0.44809 | $-$ |\n",
    "\n",
    "Full factorial designs may be too expensive in actual applications. Fractional factorial designs or optimal designs can be used to decrease costs while still providing good estimates. Screening designs are extremely cheap, and can help determine which factors can potentially be dropped on more expensive and precise designs.\n",
    "\n",
    "Check the examples directory for more tutorials!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
